"""
ASR Service - Speech-to-Text –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏
–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å—É –≥—Ä–æ–º–∞–¥—è–Ω
"""
import random
import io
import tempfile
import os
import subprocess
from typing import Optional

# –°–ø—Ä–æ–±–∞ —ñ–º–ø–æ—Ä—Ç—É OpenAI Whisper (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó)
try:
    import whisper
    WHISPER_AVAILABLE = True
    print("[ASR] OpenAI Whisper –¥–æ—Å—Ç—É–ø–Ω–∏–π ‚úÖ")
except ImportError:
    WHISPER_AVAILABLE = False
    print("[ASR] OpenAI Whisper –ù–ï –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    print("[ASR] –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å: pip install openai-whisper")

# –°–ø—Ä–æ–±–∞ —ñ–º–ø–æ—Ä—Ç—É torch (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
try:
    import torch
    import torchaudio
    TORCH_AVAILABLE = True
    print(f"[ASR] PyTorch {torch.__version__} –¥–æ—Å—Ç—É–ø–Ω–∏–π")
except ImportError as e:
    TORCH_AVAILABLE = False
    print(f"[ASR] PyTorch –ù–ï –¥–æ—Å—Ç—É–ø–Ω–∏–π: {e}")


# –î–µ–º–æ-–∑–∞–ø–∏—Ç–∏ –¥–ª—è fallback —Ä–µ–∂–∏–º—É
DEMO_QUERIES = [
    "–î–æ–±—Ä–æ–≥–æ –¥–Ω—è, —É –Ω–∞—Å –Ω–µ–º–∞—î –æ–ø–∞–ª–µ–Ω–Ω—è –≤–∂–µ –¥—Ä—É–≥–∏–π –¥–µ–Ω—å",
    "–ù–∞ –º–æ—é –º–∞—à–∏–Ω—É –≤–ø–∞–ª–æ –¥–µ—Ä–µ–≤–æ, –ø–æ—Ç—Ä—ñ–±–Ω–∞ –¥–æ–ø–æ–º–æ–≥–∞",
    "–ü—Ä–æ—Ç—ñ–∫–∞—î —Å—Ç–µ–ª—è —É –∫–≤–∞—Ä—Ç–∏—Ä—ñ, –≤–æ–¥–∞ –∫–∞–ø–∞—î",
    "–ö–æ–ª–∏ –≤—ñ–¥–∫–ª—é—á–∞—Ç–∏–º—É—Ç—å —Å–≤—ñ—Ç–ª–æ –≤ –Ω–∞—à–æ–º—É —Ä–∞–π–æ–Ω—ñ",
    "–ù–µ–º–∞—î —Ö–æ–ª–æ–¥–Ω–æ—ó –≤–æ–¥–∏ –≤ –±—É–¥–∏–Ω–∫—É –∑ —Å–∞–º–æ–≥–æ —Ä–∞–Ω–∫—É",
    "–£ –Ω–∞—Å –Ω–∞ —Ç–µ—Ä–∏—Ç–æ—Ä—ñ—ó –Ω–µ –ø—Ä–∏–±—Ä–∞–ª–∏ —Å–Ω—ñ–≥",
    "–•–æ—á—É –ø–æ—Å–∫–∞—Ä–∂–∏—Ç–∏—Å—è –Ω–∞ –≤–æ–¥—ñ—è –º–∞—Ä—à—Ä—É—Ç–∫–∏",
    "–ù–∞ –¥–æ—Ä–æ–∑—ñ –≤–µ–ª–∏—á–µ–∑–Ω–∞ —è–º–∞"
]


class ASRService:
    """Speech-to-Text —Å–µ—Ä–≤—ñ—Å –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é Whisper —Ç–∞ Silero"""
    
    def __init__(self):
        self.whisper_model = None
        self.silero_model = None
        self.device = None
        self.decoder = None
        self.utils = None
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ Whisper (–ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó)
        if WHISPER_AVAILABLE:
            self._load_whisper_model()
        
        # –Ø–∫—â–æ Whisper –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏–≤—Å—è, –ø—Ä–æ–±—É—î–º–æ Silero
        if self.whisper_model is None and TORCH_AVAILABLE:
            self._load_silero_model()
    
    def _load_whisper_model(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ Whisper"""
        try:
            print("[ASR] –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Whisper model (base)...")
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ 'base' –º–æ–¥–µ–ª—å - –¥–æ—Å—Ç–∞—Ç–Ω—å–æ —Ç–æ—á–Ω–∞ —ñ —à–≤–∏–¥–∫–∞
            self.whisper_model = whisper.load_model("base")
            print("[ASR] ‚úÖ Whisper –º–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ")
        except Exception as e:
            print(f"[ASR] ‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Whisper: {e}")
            self.whisper_model = None
    
    def _load_silero_model(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ Silero STT"""
        try:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            print(f"[ASR] –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Silero –º–æ–¥–µ–ª—ñ –Ω–∞ {self.device}...")
            
            # –°–ø—Ä–æ–±—É—î–º–æ –∑ 'uk' –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó
            try:
                self.silero_model, self.decoder, self.utils = torch.hub.load(
                    repo_or_dir='snakers4/silero-models',
                    model='silero_stt',
                    language='uk',
                    device=self.device
                )
                print(f"[ASR] ‚úÖ Silero –º–æ–¥–µ–ª—å (—É–∫—Ä–∞—ó–Ω—Å—å–∫–∞) –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –Ω–∞ {self.device}")
                return
            except AssertionError:
                print(f"[ASR] ‚ö†Ô∏è –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞ 'uk' –Ω–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è")
            
            # –Ø–∫—â–æ 'uk' –Ω–µ –ø—Ä–∞—Ü—é—î, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ 'multilingual'
            try:
                self.silero_model, self.decoder, self.utils = torch.hub.load(
                    repo_or_dir='snakers4/silero-models',
                    model='silero_stt',
                    language='multilingual',
                    device=self.device
                )
                print(f"[ASR] ‚úÖ Silero –º–æ–¥–µ–ª—å (–±–∞–≥–∞—Ç–æ–º–æ–≤–Ω–∞) –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –Ω–∞ {self.device}")
            except AssertionError:
                print(f"[ASR] ‚ö†Ô∏è –ë–∞–≥–∞—Ç–æ–º–æ–≤–Ω–∞ –≤–µ—Ä—Å—ñ—è —Ç–∞–∫–æ–∂ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                
        except Exception as e:
            print(f"[ASR] ‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Silero: {e}")
            self.silero_model = None
    
    def transcribe_file(self, audio_path: str) -> str:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ—Ñ–∞–π–ª—É"""
        # –°–ø–æ—á–∞—Ç–∫—É –ø—Ä–æ–±—É—î–º–æ Whisper
        if self.whisper_model is not None:
            return self._transcribe_with_whisper_file(audio_path)
        
        # –ü–æ—Ç—ñ–º Silero
        if self.silero_model is not None:
            return self._transcribe_with_silero_file(audio_path)
        
        # –î–µ–º–æ-—Ä–µ–∂–∏–º
        print("[ASR] transcribe_file: –º–æ–¥–µ–ª—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ, –¥–µ–º–æ-—Ä–µ–∂–∏–º")
        return self._demo_transcribe()
    
    def transcribe_bytes(self, audio_bytes: bytes) -> str:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ –∑ –±–∞–π—Ç—ñ–≤"""
        print(f"[ASR] transcribe_bytes –≤–∏–∫–ª–∏–∫–∞–Ω–æ")
        
        # –°–ø–æ—á–∞—Ç–∫—É –ø—Ä–æ–±—É—î–º–æ Whisper
        if self.whisper_model is not None:
            print("[ASR] üé§ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é Whisper")
            return self._transcribe_with_whisper_bytes(audio_bytes)
        
        # –ü–æ—Ç—ñ–º Silero
        if self.silero_model is not None:
            print("[ASR] üé§ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é Silero")
            return self._transcribe_with_silero_bytes(audio_bytes)
        
        # –î–µ–º–æ-—Ä–µ–∂–∏–º
        print("[ASR] ‚ö†Ô∏è –ú–æ–¥–µ–ª—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ - –¥–µ–º–æ-—Ä–µ–∂–∏–º")
        return self._demo_transcribe()
    
    def _convert_audio_to_wav(self, audio_bytes: bytes, input_format: str = 'webm') -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∞—É–¥—ñ–æ —É WAV —Ñ–æ—Ä–º–∞—Ç"""
        try:
            with tempfile.NamedTemporaryFile(suffix=f'.{input_format}', delete=False) as f_in:
                f_in.write(audio_bytes)
                input_path = f_in.name
            
            output_path = input_path.replace(f'.{input_format}', '.wav')
            subprocess.run([
                'ffmpeg', '-y', '-i', input_path,
                '-ar', '16000', '-ac', '1', '-f', 'wav', output_path
            ], capture_output=True, check=True)
            
            if os.path.exists(input_path):
                os.remove(input_path)
            
            return output_path
        except Exception as e:
            print(f"[ASR] –ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó: {e}")
            return None
    
    def _transcribe_with_whisper_bytes(self, audio_bytes: bytes) -> str:
        """–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ Whisper –∑ –±–∞–π—Ç—ñ–≤"""
        try:
            import numpy as np
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —É WAV
            wav_path = self._convert_audio_to_wav(audio_bytes)
            if wav_path is None:
                return self._demo_transcribe()
            
            try:
                # Whisper –æ—á—ñ–∫—É—î numpy array –∞–±–æ —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É
                result = self.whisper_model.transcribe(wav_path, language="Ukrainian")
                transcript = result["text"].strip()
                
                os.remove(wav_path)
                
                if transcript:
                    print(f"[ASR] ‚úÖ Whisper —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤: \"{transcript}\"")
                    return transcript
                else:
                    print("[ASR] ‚ö†Ô∏è Whisper –ø–æ–≤–µ—Ä–Ω—É–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                    return self._demo_transcribe()
                    
            finally:
                if os.path.exists(wav_path):
                    os.remove(wav_path)
                    
        except Exception as e:
            print(f"[ASR] ‚ùå –ü–æ–º–∏–ª–∫–∞ Whisper: {e}")
            import traceback
            traceback.print_exc()
            return self._demo_transcribe()
    
    def _transcribe_with_whisper_file(self, audio_path: str) -> str:
        """–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ Whisper –∑ —Ñ–∞–π–ª—É"""
        try:
            result = self.whisper_model.transcribe(audio_path, language="Ukrainian")
            transcript = result["text"].strip()
            print(f"[ASR] Whisper —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤: \"{transcript}\"")
            return transcript
        except Exception as e:
            print(f"[ASR] –ü–æ–º–∏–ª–∫–∞ Whisper: {e}")
            return self._demo_transcribe()
    
    def _transcribe_with_silero_bytes(self, audio_bytes: bytes) -> str:
        """–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ Silero –∑ –±–∞–π—Ç—ñ–≤"""
        try:
            import numpy as np
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —É WAV
            wav_path = self._convert_audio_to_wav(audio_bytes)
            if wav_path is None:
                return self._demo_transcribe()
            
            try:
                waveform, sample_rate = torchaudio.load(wav_path)
                
                if sample_rate != 16000:
                    resampler = torchaudio.transforms.Resample(sample_rate, 16000)
                    waveform = resampler(waveform)
                
                if waveform.shape[0] > 1:
                    waveform = waveform.mean(dim=0, keepdim=True)
                
                (read_batch, split_into_batches, read_audio, prepare_model_input) = self.utils
                input_data = prepare_model_input([waveform.squeeze()], device=self.device)
                output = self.silero_model(input_data)
                transcript = self.decoder(output[0].cpu())
                result = transcript.strip()
                
                os.remove(wav_path)
                
                print(f"[ASR] ‚úÖ Silero —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤: \"{result}\"")
                return result
                    
            finally:
                if os.path.exists(wav_path):
                    os.remove(wav_path)
                    
        except Exception as e:
            print(f"[ASR] ‚ùå –ü–æ–º–∏–ª–∫–∞ Silero: {e}")
            return self._demo_transcribe()
    
    def _transcribe_with_silero_file(self, audio_path: str) -> str:
        """–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —á–µ—Ä–µ–∑ Silero –∑ —Ñ–∞–π–ª—É"""
        try:
            (read_batch, split_into_batches, read_audio, prepare_model_input) = self.utils
            audio = read_audio(audio_path, sampling_rate=16000)
            input_data = prepare_model_input([audio], device=self.device)
            output = self.silero_model(input_data)
            transcript = self.decoder(output[0].cpu())
            result = transcript.strip()
            print(f"[ASR] Silero —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤: \"{result}\"")
            return result
        except Exception as e:
            print(f"[ASR] –ü–æ–º–∏–ª–∫–∞ Silero: {e}")
            return self._demo_transcribe()
    
    def _demo_transcribe(self) -> str:
        """–î–µ–º–æ-—Ä–µ–∂–∏–º: –ø–æ–≤–µ—Ä—Ç–∞—î –≤–∏–ø–∞–¥–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç"""
        result = random.choice(DEMO_QUERIES)
        print(f"[ASR] üé≠ –î–µ–º–æ-—Ä–µ–∂–∏–º: –≤–∏–≥–∞–¥–∞–Ω–æ \"{result}\"")
        return result


# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä
asr_service = ASRService()


def transcribe_audio(audio_path: str) -> str:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ—Ñ–∞–π–ª"""
    return asr_service.transcribe_file(audio_path)


def transcribe_audio_bytes(audio_bytes: bytes) -> str:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ –∑ –±–∞–π—Ç—ñ–≤"""
    return asr_service.transcribe_bytes(audio_bytes)
