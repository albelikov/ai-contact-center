"""
ASR Service - Speech-to-Text –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏
–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –≥–æ–ª–æ—Å—É –≥—Ä–æ–º–∞–¥—è–Ω
"""
import random
from typing import Optional

# –°–ø—Ä–æ–±–∞ —ñ–º–ø–æ—Ä—Ç—É torch (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
try:
    import torch
    import torchaudio
    TORCH_AVAILABLE = True
    TORCH_VERSION = torch.__version__
    print(f"[ASR] PyTorch {TORCH_VERSION} –¥–æ—Å—Ç—É–ø–Ω–∏–π")
except ImportError as e:
    TORCH_AVAILABLE = False
    print(f"[ASR] PyTorch –ù–ï –¥–æ—Å—Ç—É–ø–Ω–∏–π - ASR –ø—Ä–∞—Ü—é—î –≤ –¥–µ–º–æ-—Ä–µ–∂–∏–º—ñ: {e}")


# –î–µ–º–æ-–∑–∞–ø–∏—Ç–∏ –¥–ª—è fallback —Ä–µ–∂–∏–º—É
DEMO_QUERIES = [
    "–î–æ–±—Ä–æ–≥–æ –¥–Ω—è, —É –Ω–∞—Å –Ω–µ–º–∞—î –æ–ø–∞–ª–µ–Ω–Ω—è –≤–∂–µ –¥—Ä—É–≥–∏–π –¥–µ–Ω—å",
    "–ù–∞ –º–æ—é –º–∞—à–∏–Ω—É –≤–ø–∞–ª–æ –¥–µ—Ä–µ–≤–æ, –ø–æ—Ç—Ä—ñ–±–Ω–∞ –¥–æ–ø–æ–º–æ–≥–∞",
    "–ü—Ä–æ—Ç—ñ–∫–∞—î —Å—Ç–µ–ª—è —É –∫–≤–∞—Ä—Ç–∏—Ä—ñ, –≤–æ–¥–∞ –∫–∞–ø–∞—î",
    "–ö–æ–ª–∏ –≤—ñ–¥–∫–ª—é—á–∞—Ç–∏–º—É—Ç—å —Å–≤—ñ—Ç–ª–æ –≤ –Ω–∞—à–æ–º—É —Ä–∞–π–æ–Ω—ñ",
    "–ù–µ–º–∞—î —Ö–æ–ª–æ–¥–Ω–æ—ó –≤–æ–¥–∏ –≤ –±—É–¥–∏–Ω–∫—É –∑ —Å–∞–º–æ–≥–æ —Ä–∞–Ω–∫—É",
    "–£ –Ω–∞—Å –Ω–∞ —Ç–µ—Ä–∏—Ç–æ—Ä—ñ—ó –Ω–µ –ø—Ä–∏–±—Ä–∞–ª–∏ —Å–Ω—ñ–≥",
    "–•–æ—á—É –ø–æ—Å–∫–∞—Ä–∂–∏—Ç–∏—Å—è –Ω–∞ –≤–æ–¥—ñ—è –º–∞—Ä—à—Ä—É—Ç–∫–∏",
    "–ù–∞ –¥–æ—Ä–æ–∑—ñ –≤–µ–ª–∏—á–µ–∑–Ω–∞ —è–º–∞"
]


class ASRService:
    """Speech-to-Text —Å–µ—Ä–≤—ñ—Å"""
    
    def __init__(self):
        self.model = None
        self.device = None
        
        if TORCH_AVAILABLE:
            self._load_silero_model()
    
    def _load_silero_model(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ Silero STT"""
        try:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            print(f"[ASR] –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Silero –º–æ–¥–µ–ª—ñ –Ω–∞ {self.device}...")
            self.model, self.decoder, self.utils = torch.hub.load(
                repo_or_dir='snakers4/silero-models',
                model='silero_stt',
                language='uk',
                device=self.device
            )
            print(f"[ASR] ‚úÖ Silero –º–æ–¥–µ–ª—å —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –Ω–∞ {self.device}")
        except Exception as e:
            print(f"[ASR] ‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Silero: {e}")
            import traceback
            traceback.print_exc()
            self.model = None
    
    def transcribe_file(self, audio_path: str) -> str:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ—Ñ–∞–π–ª—É"""
        if self.model is None:
            print("[ASR] transcribe_file: –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –¥–µ–º–æ-—Ä–µ–∂–∏–º")
            return self._demo_transcribe()
        
        try:
            (read_batch, split_into_batches, read_audio, prepare_model_input) = self.utils
            audio = read_audio(audio_path, sampling_rate=16000)
            input_data = prepare_model_input([audio], device=self.device)
            output = self.model(input_data)
            transcript = self.decoder(output[0].cpu())
            result = transcript.strip()
            print(f"[ASR] transcribe_file: —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ \"{result}\"")
            return result
        except Exception as e:
            print(f"[ASR] transcribe_file –ø–æ–º–∏–ª–∫–∞: {e}")
            return self._demo_transcribe()
    
    def transcribe_bytes(self, audio_bytes: bytes) -> str:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ –∑ –±–∞–π—Ç—ñ–≤"""
        print(f"[ASR] transcribe_bytes –≤–∏–∫–ª–∏–∫–∞–Ω–æ, TORCH_AVAILABLE={TORCH_AVAILABLE}, model={self.model is not None}")
        
        if not TORCH_AVAILABLE or self.model is None:
            print("[ASR] ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ - –¥–µ–º–æ-—Ä–µ–∂–∏–º (–≤–∏–≥–∞–¥—É—î —Ñ—Ä–∞–∑—É)")
            return self._demo_transcribe()
        
        print(f"[ASR] üé§ –ü–æ—á–∏–Ω–∞—é —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ ({len(audio_bytes)} –±–∞–π—Ç)...")
        
        try:
            import io
            import tempfile
            import subprocess
            import os
            
            # –°–ø—Ä–æ–±—É—î–º–æ –≤–∏–∑–Ω–∞—á–∏—Ç–∏ —Ñ–æ—Ä–º–∞—Ç —ñ –∫–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
            audio_buffer = io.BytesIO(audio_bytes)
            
            # –°–ø–µ—Ä—à—É —Å–ø—Ä–æ–±—É—î–º–æ –Ω–∞–ø—Ä—è–º—É
            try:
                waveform, sample_rate = torchaudio.load(audio_buffer)
            except Exception as load_error:
                print(f"[ASR] –ü—Ä—è–º–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–µ –≤–¥–∞–ª–æ—Å—è: {load_error}")
                # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —á–µ—Ä–µ–∑ ffmpeg
                with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as f_in:
                    f_in.write(audio_bytes)
                    input_path = f_in.name
                
                output_path = input_path.replace('.webm', '.wav')
                try:
                    subprocess.run([
                        'ffmpeg', '-y', '-i', input_path,
                        '-ar', '16000', '-ac', '1', '-f', 'wav', output_path
                    ], capture_output=True, check=True)
                    
                    waveform, sample_rate = torchaudio.load(output_path)
                finally:
                    # –û—á–∏—â—É—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤—ñ —Ñ–∞–π–ª–∏
                    if os.path.exists(input_path):
                        os.remove(input_path)
                    if os.path.exists(output_path):
                        os.remove(output_path)
            
            if sample_rate != 16000:
                resampler = torchaudio.transforms.Resample(sample_rate, 16000)
                waveform = resampler(waveform)
            
            if waveform.shape[0] > 1:
                waveform = waveform.mean(dim=0, keepdim=True)
            
            (read_batch, split_into_batches, read_audio, prepare_model_input) = self.utils
            input_data = prepare_model_input([waveform.squeeze()], device=self.device)
            output = self.model(input_data)
            transcript = self.decoder(output[0].cpu())
            result = transcript.strip()
            print(f"[ASR] ‚úÖ –†–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ: \"{result}\"")
            return result
        except Exception as e:
            print(f"[ASR] ‚ùå –ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è: {e}")
            import traceback
            traceback.print_exc()
            print("[ASR] ‚ö†Ô∏è –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é –¥–µ–º–æ-—Ä–µ–∂–∏–º —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫—É")
            return self._demo_transcribe()
    
    def _demo_transcribe(self) -> str:
        """–î–µ–º–æ-—Ä–µ–∂–∏–º: –ø–æ–≤–µ—Ä—Ç–∞—î –≤–∏–ø–∞–¥–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç"""
        result = random.choice(DEMO_QUERIES)
        print(f"[ASR] üé≠ –î–µ–º–æ-—Ä–µ–∂–∏–º: –≤–∏–≥–∞–¥–∞–Ω–æ \"{result}\"")
        return result


# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä
asr_service = ASRService()


def transcribe_audio(audio_path: str) -> str:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ—Ñ–∞–π–ª"""
    return asr_service.transcribe_file(audio_path)


def transcribe_audio_bytes(audio_bytes: bytes) -> str:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ –∑ –±–∞–π—Ç—ñ–≤"""
    return asr_service.transcribe_bytes(audio_bytes)
